{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z9t51Zd1RAdt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5449,
     "status": "ok",
     "timestamp": 1692988738670,
     "user": {
      "displayName": "Parag Bhatt",
      "userId": "11827230773587162498"
     },
     "user_tz": 300
    },
    "id": "z9t51Zd1RAdt",
    "outputId": "d5e31c7a-39a9-4758-9d02-462ee8e06447"
   },
   "outputs": [],
   "source": [
    "# Matplotlib enables us to plot within the notebook, matplotlib is very powerful plotting library\n",
    "%matplotlib widget\n",
    "# Imports additional packages to interact with your operating system (os),\n",
    "# computer vision tasks (cv2), to retrieve files/pathnames that match a specified pattern (glob)\n",
    "import os, cv2, glob\n",
    "# Imports NumPy package into notebook, essential for scientific computing\n",
    "import numpy as np\n",
    "# Imports PlantCV into notebook so that we can conduct plant phenotyping analyses\n",
    "from plantcv import plantcv as pcv\n",
    "# Imports PyPlot which will provides us a MATLAB-like interface\n",
    "from matplotlib import pyplot as plt\n",
    "# Imports Pandas which supports R-like dataframes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-wound",
   "metadata": {
    "id": "talented-wound"
   },
   "source": [
    "## Locate filepaths of all data saved out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-sierra",
   "metadata": {
    "id": "harmful-sierra"
   },
   "outputs": [],
   "source": [
    "# Get current working directory (the file path where is this notebook located?)\n",
    "path = os.getcwd()\n",
    "\n",
    "# Any file with .csv file extension will get stored into list of csv filename\n",
    "csv_filenames = glob.glob(os.path.join(path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-separate",
   "metadata": {
    "id": "found-separate"
   },
   "outputs": [],
   "source": [
    "# Do you have as many data filenames as expected?\n",
    "csv_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-slave",
   "metadata": {
    "id": "driving-slave"
   },
   "outputs": [],
   "source": [
    "# Define empty list for storing our various dataframes\n",
    "data_list = []\n",
    "\n",
    "# loop over the list of csv files\n",
    "for f in csv_filenames:\n",
    "\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    # Append to the list called data_list\n",
    "    data_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-illustration",
   "metadata": {
    "id": "exotic-illustration"
   },
   "outputs": [],
   "source": [
    "# Concatenate (combine) all dataframes into a single dataframe\n",
    "all_data = pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-adapter",
   "metadata": {
    "id": "regular-adapter"
   },
   "outputs": [],
   "source": [
    "# Data wrangling steps\n",
    "# a.k.a. change the shape (structure) of the dataframe into compatible format for next steps\n",
    "\n",
    "# Filter the traits kept\n",
    "bean_features = all_data[all_data['trait'].isin(['area', 'convex_hull_area', 'solidity',\n",
    "                                                   'perimeter', 'width', 'height', 'ellipse_major_axis',\n",
    "                                                   'ellipse_minor_axis', 'ellipse_eccentricity',\n",
    "                                                   'hue_circular_mean', 'hue_median'])]\n",
    "\n",
    "# Pivot (Transform) the dataframe from \"long\" format to \"wide\"\n",
    "bean_features_wide = pd.pivot(bean_features, index=['sample',\n",
    "                                                    'median_color_chip_size',\n",
    "                                                    'median_color_chip_width'],\n",
    "                              columns=\"trait\", values=\"value\", )\n",
    "\n",
    "# Convert the multiindex to a single index\n",
    "bean_features_wide = bean_features_wide.reset_index(level=[\"median_color_chip_size\", \"median_color_chip_width\"])\n",
    "\n",
    "# Scale area and length measurements by the color card chip measurements\n",
    "bean_features_wide[\"area\"] = bean_features_wide[\"area\"] / bean_features_wide[\"median_color_chip_size\"]\n",
    "bean_features_wide[\"convex_hull_area\"] = bean_features_wide[\"convex_hull_area\"] / bean_features_wide[\"median_color_chip_size\"]\n",
    "bean_features_wide[\"ellipse_major_axis\"] = bean_features_wide[\"ellipse_major_axis\"] / bean_features_wide[\"median_color_chip_width\"]\n",
    "bean_features_wide[\"ellipse_minor_axis\"] = bean_features_wide[\"ellipse_minor_axis\"] / bean_features_wide[\"median_color_chip_width\"]\n",
    "bean_features_wide[\"perimeter\"] = bean_features_wide[\"perimeter\"] / bean_features_wide[\"median_color_chip_width\"]\n",
    "bean_features_wide[\"width\"] = bean_features_wide[\"width\"] / bean_features_wide[\"median_color_chip_width\"]\n",
    "\n",
    "bean_features_wide = bean_features_wide.drop([\"median_color_chip_size\", \"median_color_chip_width\"], axis=1)\n",
    "\n",
    "# Cast (change data type) to numpy array\n",
    "np_features = bean_features_wide.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-context",
   "metadata": {
    "id": "reasonable-context"
   },
   "outputs": [],
   "source": [
    "# Investigate the formatted data\n",
    "bean_features_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-florida",
   "metadata": {
    "id": "appropriate-florida"
   },
   "outputs": [],
   "source": [
    "# Extract list of traits\n",
    "trait_list = bean_features_wide.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-saturn",
   "metadata": {
    "id": "alpha-saturn"
   },
   "outputs": [],
   "source": [
    "# Collect list of labels\n",
    "labels = []\n",
    "for name in trait_list:\n",
    "    bean_num = name.split(\"_\")[0]\n",
    "    labels.append(bean_num)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-portrait",
   "metadata": {
    "id": "announced-portrait"
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-generator",
   "metadata": {
    "id": "agreed-generator"
   },
   "source": [
    "Feed the trait data into the Random Forest Classifier. Giving the function data to train a model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-facing",
   "metadata": {
    "id": "popular-facing"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = np_features\n",
    "y_train = labels\n",
    "\n",
    "feature_names = list(bean_features_wide.columns)\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-albert",
   "metadata": {
    "id": "printable-albert"
   },
   "outputs": [],
   "source": [
    "# Extract feature importances from the model created, and standard deviations for each\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-earth",
   "metadata": {
    "id": "reflected-earth"
   },
   "outputs": [],
   "source": [
    "# Create a plot to display\n",
    "\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-exchange",
   "metadata": {
    "id": "adaptive-exchange"
   },
   "source": [
    "# STOP ðŸ›‘  HERE !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-dominican",
   "metadata": {
    "id": "distinct-dominican"
   },
   "source": [
    "Below this point is an example of how to use a trained classifier on unlabeled data, getting collected from a bean scatter image with mixed bean types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-times",
   "metadata": {
    "id": "complicated-times"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-spank",
   "metadata": {
    "id": "stupid-spank"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-burst",
   "metadata": {
    "id": "indie-burst"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-wedding",
   "metadata": {
    "id": "neural-wedding"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "outside-contamination",
   "metadata": {
    "id": "outside-contamination"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "# Take a bean scatter image and extract traits\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-queensland",
   "metadata": {
    "id": "mediterranean-queensland"
   },
   "outputs": [],
   "source": [
    "# Turn debugging images on\n",
    "pcv.params.debug = \"plot\"\n",
    "\n",
    "# Read image\n",
    "\n",
    "# Inputs:\n",
    "#   filename - Image file to be read in\n",
    "#   mode - How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\n",
    "\n",
    "# Read in bean scatter image\n",
    "img, path, filename = pcv.readimage(filename=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-dream",
   "metadata": {
    "id": "olympic-dream"
   },
   "outputs": [],
   "source": [
    "# Why are they directly extracting the B*?\n",
    "# Inputs:\n",
    "#   rbg_img - original image\n",
    "#   channel - desired colorspace ('l', 'a', or 'b')\n",
    "\n",
    "gray = pcv.rgb2gray_lab(rgb_img=img, channel=\"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-editing",
   "metadata": {
    "id": "criminal-editing"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   gray_img    = grayscale image created from selected colorspace\n",
    "\n",
    "auto_mask = pcv.threshold.otsu(gray_img=gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-encyclopedia",
   "metadata": {
    "id": "asian-encyclopedia"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "# Set Region Of Interest\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-printer",
   "metadata": {
    "id": "little-printer"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img         = RGB or grayscale image for plotting\n",
    "#   x           = x coordinate of the center of ROI\n",
    "#   y           = y coordinate of the center of ROI\n",
    "#   r           = radius of the ROI to get drawn\n",
    "\n",
    "\n",
    "roi = pcv.roi.rectangle(img=img, x=100, y=2000, h=1900, w=2800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-freeze",
   "metadata": {
    "id": "mineral-freeze"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   mask         = Binary image\n",
    "#   roi          = Region of interest, defined in an upstream step\n",
    "#   roi_type     = 'cutto', 'partial' (for partially inside, default), or\n",
    "#                 'largest' (keep only the largest contour)\n",
    "\n",
    "filtered_mask = pcv.roi.filter(mask=auto_mask, roi=roi, roi_type=\"partial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-facility",
   "metadata": {
    "id": "pacific-facility"
   },
   "outputs": [],
   "source": [
    "pcv.params.text_size = 5\n",
    "pcv.params.text_thickness = 5\n",
    "\n",
    "# Inputs:\n",
    "#   img         = gray image in selected colorspace\n",
    "#   mask        = None (default), or mask\n",
    "#   num_objects = Optional parameter to limit the number of objects that will get annotated.\n",
    "\n",
    "sizes = pcv.visualize.obj_sizes(img=img, mask=filtered_mask, num_objects=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-duplicate",
   "metadata": {
    "id": "incident-duplicate"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "#   size - maximum size for objects that should be filled in as background (non-plant) pixels\n",
    "fill = pcv.fill(bin_img=filtered_mask, size=1000)\n",
    "#                                            ^\n",
    "#                                           |\n",
    "#                                 change this value if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-milwaukee",
   "metadata": {
    "id": "jewish-milwaukee"
   },
   "outputs": [],
   "source": [
    "# Flood fill\n",
    "\n",
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "\n",
    "clean_mask = pcv.fill_holes(bin_img=fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-exploration",
   "metadata": {
    "id": "offshore-exploration"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#    mask            = mask image\n",
    "#    rois            = (Optional) list of multiple ROIs (from roi.multi or roi.auto_grid)\n",
    "#    roi_type        = (Optional) type of filtering, either partial' (for partially inside, default),\n",
    "#                       cutto' (hard cut at boundary), 'largest' (keep only the largest contour)\n",
    "\n",
    "labeled_mask, num = pcv.create_labels(mask=clean_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-bearing",
   "metadata": {
    "id": "loving-bearing"
   },
   "outputs": [],
   "source": [
    "# Extract size traits\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging\n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "\n",
    "shape_img = pcv.analyze.size(img=img, labeled_mask=labeled_mask, n_labels=num, label=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9644204-7a91-4617-bfb1-a7da43bfba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# ----------\n",
    "# rgb_img : numpy.ndarray\n",
    "#     Input RGB image data containing a color card.\n",
    "# label : str, optional\n",
    "#     modifies the variable name of observations recorded (default = pcv.params.sample_label).\n",
    "# **kwargs\n",
    "#     Other keyword arguments passed to cv2.adaptiveThreshold and cv2.circle.\n",
    "\n",
    "#     Valid keyword arguments:\n",
    "#     adaptive_method: 0 (mean) or 1 (Gaussian) (default = 1)\n",
    "#     block_size: int (default = 51)\n",
    "#     radius: int (default = 20)\n",
    "\n",
    "cc_mask = pcv.transform.detect_color_card(rgb_img=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ca94c-cad8-4142-82e9-86c7979132b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions extract color matrices for the image and a standard set of values\n",
    "_, color_mat = pcv.transform.get_color_matrix(rgb_img=img, mask=cc_mask)\n",
    "std_mat = pcv.transform.std_color_matrix(pos=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d5c12-531b-4133-911d-f8e787b37759",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_img = pcv.transform.affine_color_correction(rgb_img=img,\n",
    "                                               source_matrix=color_mat,\n",
    "                                               target_matrix=std_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb690d-1e63-42f6-903a-f4f902d9cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the median chip area\n",
    "pcv.outputs.add_metadata(term=\"median_color_chip_size\",\n",
    "                         datatype=float,\n",
    "                         value=pcv.outputs.observations[\"default\"][\"median_color_chip_size\"][\"value\"])\n",
    "# Save the median chip width\n",
    "pcv.outputs.add_metadata(term=\"median_color_chip_width\",\n",
    "                         datatype=float,\n",
    "                         value=pcv.outputs.observations[\"default\"][\"median_color_chip_width\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-leader",
   "metadata": {
    "id": "sized-leader"
   },
   "outputs": [],
   "source": [
    "# Extract color traits from each replicate\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging\n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   colorspaces  = 'all', 'rgb', 'lab', or 'hsv' (default = 'hsv').\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "\n",
    "color_img = pcv.analyze.color(rgb_img=cc_img, labeled_mask=labeled_mask, n_labels=num, label=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-eagle",
   "metadata": {
    "id": "ordinary-eagle"
   },
   "outputs": [],
   "source": [
    "# Save out unclassified bean trait data\n",
    "pcv.outputs.save_results(\"unclassified_bean_data.csv\", \"csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-spouse",
   "metadata": {
    "id": "vertical-spouse"
   },
   "outputs": [],
   "source": [
    "# Read in CSV data and train on X traits\n",
    "f2 = \"unclassified_bean_data.csv\"\n",
    "df2 = pd.read_csv(f2)\n",
    "\n",
    "# Filter the traits kept\n",
    "bean_features2 = df2[df2['trait'].isin(['area', 'convex_hull_area', 'solidity',\n",
    "                                     'perimeter', 'width', 'height', 'ellipse_major_axis',\n",
    "                                     'ellipse_minor_axis', 'ellipse_eccentricity',\n",
    "                                     'hue_circular_mean', 'hue_median'])]\n",
    "\n",
    "# Pivot the dataframe from \"long\" format to \"wide\"\n",
    "bean_features_wide2 = pd.pivot(bean_features2, index=['sample',\n",
    "                                                      'median_color_chip_size',\n",
    "                                                      'median_color_chip_width'],\n",
    "                               columns=\"trait\", values=\"value\")\n",
    "\n",
    "# Convert the multiindex to a single index\n",
    "bean_features_wide2 = bean_features_wide2.reset_index(level=[\"median_color_chip_size\", \"median_color_chip_width\"])\n",
    "\n",
    "# Scale area and length measurements by the color card chip measurements\n",
    "bean_features_wide2[\"area\"] = bean_features_wide2[\"area\"] / bean_features_wide2[\"median_color_chip_size\"]\n",
    "bean_features_wide2[\"convex_hull_area\"] = bean_features_wide2[\"convex_hull_area\"] / bean_features_wide2[\"median_color_chip_size\"]\n",
    "bean_features_wide2[\"ellipse_major_axis\"] = bean_features_wide2[\"ellipse_major_axis\"] / bean_features_wide2[\"median_color_chip_width\"]\n",
    "bean_features_wide2[\"ellipse_minor_axis\"] = bean_features_wide2[\"ellipse_minor_axis\"] / bean_features_wide2[\"median_color_chip_width\"]\n",
    "bean_features_wide2[\"perimeter\"] = bean_features_wide2[\"perimeter\"] / bean_features_wide2[\"median_color_chip_width\"]\n",
    "bean_features_wide2[\"width\"] = bean_features_wide2[\"width\"] / bean_features_wide2[\"median_color_chip_width\"]\n",
    "\n",
    "# Remove the chip size features\n",
    "bean_features_wide2 = bean_features_wide2.drop([\"median_color_chip_size\", \"median_color_chip_width\"], axis=1)\n",
    "\n",
    "# Cast to numpy array\n",
    "np_features2 = bean_features_wide2.to_numpy()\n",
    "\n",
    "# Extrat list of traits\n",
    "trait_list2 = bean_features_wide2.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-poison",
   "metadata": {
    "id": "loaded-poison"
   },
   "outputs": [],
   "source": [
    "# Then predict instead of forest.fit\n",
    "X_class = np_features2\n",
    "\n",
    "classifier = forest.predict(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-vatican",
   "metadata": {
    "id": "taken-vatican"
   },
   "outputs": [],
   "source": [
    "# Investigate the predictions\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-cocktail",
   "metadata": {
    "id": "helpful-cocktail"
   },
   "outputs": [],
   "source": [
    "# Combine the predictions with PlantCV data that marks the location of each bean in the image\n",
    "classes = pd.DataFrame({\"sample\": bean_features_wide2.index.tolist(), \"class\": classifier.tolist()})\n",
    "classes = classes.merge(df2.loc[(df2[\"trait\"] == \"center_of_mass\") & (df2[\"label\"] == \"x\")])\n",
    "classes.drop([\"trait\", \"label\"], axis=1, inplace=True)\n",
    "classes.rename({\"value\": \"cmx\"}, inplace=True, axis=1)\n",
    "classes = classes.merge(df2.loc[(df2[\"trait\"] == \"center_of_mass\") & (df2[\"label\"] == \"y\")])\n",
    "classes.drop([\"trait\", \"label\"], axis=1, inplace=True)\n",
    "classes.rename({\"value\": \"cmy\"}, inplace=True, axis=1)\n",
    "\n",
    "# Label the bean class next to each bean on the image\n",
    "outimg = img.copy()\n",
    "for index, row in classes.iterrows():\n",
    "    cv2.putText(img=outimg, text=row[\"class\"], org=(int(row[\"cmx\"]), int(row[\"cmy\"])),\n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=pcv.params.text_size,\n",
    "                color=(255, 255, 255), thickness=pcv.params.text_thickness)\n",
    "pcv.plot_image(outimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-differential",
   "metadata": {
    "id": "personalized-differential"
   },
   "outputs": [],
   "source": [
    "# Print out a table of the probability each bean belongs to each category/class\n",
    "print(forest.classes_)\n",
    "forest.predict_proba(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-stuart",
   "metadata": {
    "id": "entitled-stuart"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
