{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "developed-lying",
   "metadata": {
    "id": "developed-lying"
   },
   "source": [
    "<span style=\"color:maroon\">\n",
    "\n",
    "# Extract traits from bean images\n",
    "    \n",
    "## =====================================================================\n",
    "\n",
    "## BLANK Bean Example\n",
    "## =====================================================================\n",
    "\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-lightweight",
   "metadata": {
    "id": "graphic-lightweight"
   },
   "source": [
    "We want to extract traits about different beans. We will measure these traits using image analysis and save data into a CSV for Machine Learning in a later activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-stadium",
   "metadata": {
    "id": "brazilian-stadium"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "Headers in purple will indicate a step that **might** need adjusting to parameterize the workflow to your particular image.\n",
    "    \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-figure",
   "metadata": {
    "id": "prospective-figure"
   },
   "source": [
    "## August 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z9t51Zd1RAdt",
   "metadata": {
    "id": "z9t51Zd1RAdt"
   },
   "outputs": [],
   "source": [
    "# Matplotlib enables us to plot within the notebook, matplotlib is very powerful plotting library\n",
    "%matplotlib widget\n",
    "# Imports PlantCV into notebook so that we can conduct plant phenotyping analyses\n",
    "from plantcv import plantcv as pcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-interference",
   "metadata": {
    "id": "strange-interference",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print out the version of PlantCV being used by the Jupyter kernel\n",
    "pcv.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-specialist",
   "metadata": {
    "id": "african-specialist"
   },
   "source": [
    "# Initialize workflow inputs & outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-theta",
   "metadata": {
    "id": "accomplished-theta",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set debugging parameters\n",
    "pcv.params.debug = \"plot\"\n",
    "pcv.params.text_size = 25\n",
    "pcv.params.text_thickness = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-aging",
   "metadata": {
    "id": "prospective-aging"
   },
   "source": [
    "\n",
    "What exactly is a filepath? In general, a path is a string of characters which specifies a unique location in a directory or page hierarchy. For file systems, each level in the hierarchy is a directory.\n",
    "\n",
    "`/home/user/python/test.py`\n",
    "\n",
    "In this file path, the test.py file is inside the python directory. The python directory is a subdirectory of the user directory, which is a subdirectory of the home directory. Absolute file paths specify the location of a file from the root directory in the file system structure. They are also called “full file paths” or “full paths.” In Linux, the tilde (~) is commonly used to represent a user’s home directory in a file path. Relative file paths specify the location of a file in the same folder or on the same server. In other words, a relative file path specifies a location of a file that is relative to the current directory.\n",
    "\n",
    "\n",
    "(https://www.codecademy.com/resources/docs/general/file-paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-fifteen",
   "metadata": {
    "id": "animated-fifteen"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "\n",
    "## Read in the image\n",
    "    \n",
    "File extension is case sensitive.\n",
    "    \n",
    "Helpful notes about best practices on taking images for analysis https://danforth.workvivo.com/file/420146\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-salmon",
   "metadata": {
    "id": "wooden-salmon",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "\n",
    "# Inputs:\n",
    "#   filename - Image file to be read in\n",
    "#   mode - How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\n",
    "\n",
    "img, path1, filename1 = pcv.readimage(filename=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-photography",
   "metadata": {
    "id": "robust-photography"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "    \n",
    "# Rename your bean type\n",
    "\n",
    "### Use CamelCase and\n",
    "## avoid spaces or underscores !!!\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-bobby",
   "metadata": {
    "id": "absent-bobby"
   },
   "outputs": [],
   "source": [
    "bean_name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-cross",
   "metadata": {
    "id": "appropriate-cross"
   },
   "source": [
    "## Visualize Colorspaces\n",
    "The visualization tool converts the color image into HSV, LAB, and CMYK colorspaces and displays the grayscale channels in a matrix so that they can be visualized simultaneously. The idea is to select a channel that maximizes the difference between the plant and the background pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-office",
   "metadata": {
    "id": "inclusive-office"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   rbg_img      = original image\n",
    "#   original_img = whether to include the original RGB images in the display: True (default) or False\n",
    "\n",
    "all_c = pcv.visualize.colorspaces(rgb_img=,\n",
    "                                  original_img=False\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-hearts",
   "metadata": {
    "id": "played-hearts"
   },
   "source": [
    "## Convert the color image to grayscale\n",
    "Converts the input color image into the LAB colorspace and returns the B (blue-yellow) channel as a grayscale image. We have already tested ever type of bean and found that \"b\" channel did well (since we chose a blue background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-trading",
   "metadata": {
    "id": "official-trading"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   rbg_img - original image\n",
    "#   channel - desired colorspace ('l', 'a', or 'b')\n",
    "\n",
    "gray = pcv.rgb2gray_lab(rgb_img=,\n",
    "                        channel=\"\"\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-cooperative",
   "metadata": {
    "id": "superb-cooperative"
   },
   "source": [
    "# Visualize the distribution of grayscale values\n",
    "A histogram can be used to visualize the distribution of values in an image. The histogram can aid in the selection of a threshold value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-muscle",
   "metadata": {
    "id": "standard-muscle"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img         = gray image in selected colorspace\n",
    "#   mask        = None (default), or mask\n",
    "#   bins        = 100 (default) or number of desired number of evenly spaced bins\n",
    "#   lower-bound = None (default) or minimum value on x-axis\n",
    "#   upper-bound = None (default) or maximum value on x-axis\n",
    "#   title       = None (default) or custom plot title\n",
    "#   hist_data   = False (default) or True (if frequency distribution data is desired)\n",
    "\n",
    "hist = pcv.visualize.histogram(img=,\n",
    "                               bins=30\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-paper",
   "metadata": {
    "id": "infrared-paper"
   },
   "source": [
    "## Threshold the grayscale image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-attack",
   "metadata": {
    "id": "global-attack"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   gray_img    = grayscale image created from selected colorspace\n",
    "\n",
    "bin_mask = pcv.threshold.otsu(gray_img=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-register",
   "metadata": {
    "id": "polish-register"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "    \n",
    "# Define Region of Interest    \n",
    "    \n",
    "_Highly likely that this step will need the parameters adjusted to each image_\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-scheduling",
   "metadata": {
    "id": "obvious-scheduling"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img           = An RGB or grayscale image to plot the ROI on in debug mode.\n",
    "#   x             = The x-coordinate of the upper left corner of the rectangle.\n",
    "#   y             = The y-coordinate of the upper left corner of the rectangle.\n",
    "#   h             = The height of the rectangle.\n",
    "#   w             = The width of the rectangle.\n",
    "\n",
    "roi = pcv.roi.rectangle(img=img,\n",
    "                        x=,\n",
    "                        y=,\n",
    "                        h=,\n",
    "                        w=\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-certificate",
   "metadata": {
    "id": "fifth-certificate"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   mask         = Binary image\n",
    "#   roi          = Region of interest, defined in an upstream step\n",
    "#   roi_type     = 'cutto', 'partial' (for partially inside, default), or\n",
    "#                  'largest' (keep only the largest contour)\n",
    "\n",
    "filtered_mask = pcv.roi.filter(mask=,\n",
    "                               roi=,\n",
    "                               roi_type=\"partial\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-architect",
   "metadata": {
    "id": "amazing-architect"
   },
   "source": [
    "## Investigate object sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-corner",
   "metadata": {
    "id": "proved-corner"
   },
   "outputs": [],
   "source": [
    "pcv.params.text_size = 6\n",
    "pcv.params.text_thickness = 5\n",
    "\n",
    "# Inputs:\n",
    "#   img         = gray image in selected colorspace\n",
    "#   mask        = None (default), or mask\n",
    "#   num_objects = Optional parameter to limit the number of objects that will get annotated (default = 100).\n",
    "\n",
    "sizes = pcv.visualize.obj_sizes(img=img,\n",
    "                                mask=,\n",
    "                                num_objects=100\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-phrase",
   "metadata": {
    "id": "fabulous-phrase"
   },
   "source": [
    "Salt & pepper noise are small white/black pixels, respectively, in the binary mask. In this example image, the flash creates a glare that makes the centers of the beans get excluded during segmentation, but we can recover these pixels with some clean up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-communications",
   "metadata": {
    "id": "choice-communications"
   },
   "source": [
    "<span style=\"color:purple\">\n",
    "\n",
    "\n",
    "## Remove small background noise\n",
    "    \n",
    "_Thresholding mostly labeled plant pixels white but also labeled small regions of the background white. The fill function removes \"salt\" noise from the background by filtering white regions by size. The resolution of the image will factor into the average object sizes in your images so this step might require adjustment._\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-builder",
   "metadata": {
    "id": "average-builder"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "#   size - maximum size for objects that should be filled in as background (non-plant) pixels\n",
    "\n",
    "fill_mask = pcv.fill(bin_img=,\n",
    "                     size=\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-friend",
   "metadata": {
    "id": "quality-friend"
   },
   "source": [
    "## Flood fill \"pepper\" noise\n",
    "\n",
    "The `pcv.fill_holes` function does a flood fill of any missing portions that are surrounded by white pixels. This will address the glare in the center of each bean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-remark",
   "metadata": {
    "id": "therapeutic-remark"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "\n",
    "clean_mask = pcv.fill_holes(bin_img=\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-memorabilia",
   "metadata": {
    "id": "liberal-memorabilia"
   },
   "source": [
    "## Create labeled mask\n",
    "We want to extract traits from each bean replicate, so we need to create a mask that has unique pixel values for each identified object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-camping",
   "metadata": {
    "id": "horizontal-camping"
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#    mask            = mask image\n",
    "#    rois            = (Optional) list of multiple ROIs (from roi.multi or roi.auto_grid)\n",
    "#    roi_type        = (Optional)''partial' (for partially inside, default), cutto' (hard cut at boundary),\n",
    "#                      'largest' (keep only the largest contour)\n",
    "\n",
    "labeled_mask, num = pcv.create_labels(mask=\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-customs",
   "metadata": {
    "id": "alive-customs"
   },
   "source": [
    "## Extract seed shape and color traits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-summit",
   "metadata": {
    "id": "formal-summit"
   },
   "outputs": [],
   "source": [
    "# Extract size traits\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging\n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "\n",
    "shape_img = pcv.analyze.size(img=img,\n",
    "                             labeled_mask=,\n",
    "                             n_labels=,\n",
    "                             label=str(bean_name)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4083ff64-19ab-4eb6-9227-879d7bbc7da8",
   "metadata": {},
   "source": [
    "## Normalize the image color values\n",
    "We will automatically detect the color reference card and use it to normalize the image color values before we do color analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac6e21-d2fc-434e-82f8-2aedc90c2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# ----------\n",
    "# rgb_img : numpy.ndarray\n",
    "#     Input RGB image data containing a color card.\n",
    "# label : str, optional\n",
    "#     modifies the variable name of observations recorded (default = pcv.params.sample_label).\n",
    "# **kwargs\n",
    "#     Other keyword arguments passed to cv2.adaptiveThreshold and cv2.circle.\n",
    "\n",
    "#     Valid keyword arguments:\n",
    "#     adaptive_method: 0 (mean) or 1 (Gaussian) (default = 1)\n",
    "#     block_size: int (default = 51)\n",
    "#     radius: int (default = 20)\n",
    "\n",
    "cc_mask = pcv.transform.detect_color_card(rgb_img=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-january",
   "metadata": {
    "id": "divine-january"
   },
   "outputs": [],
   "source": [
    "# These functions extract color matrices for the image and a standard set of values\n",
    "_, color_mat = pcv.transform.get_color_matrix(rgb_img=img, mask=cc_mask)\n",
    "std_mat = pcv.transform.std_color_matrix(pos=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ca6da-6375-4cc6-bdfe-8e2e1566ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_img = pcv.transform.affine_color_correction(rgb_img=img,\n",
    "                                               source_matrix=color_mat,\n",
    "                                               target_matrix=std_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d982c0c6-feed-4ed8-8e14-550377ce3afb",
   "metadata": {},
   "source": [
    "## Store the size of the color card chips for size normalization later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925c655-8538-4a07-bb96-68ae489d392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the median chip area\n",
    "pcv.outputs.add_metadata(term=\"median_color_chip_size\",\n",
    "                         datatype=float,\n",
    "                         value=pcv.outputs.observations[\"default\"][\"median_color_chip_size\"][\"value\"])\n",
    "# Save the median chip width\n",
    "pcv.outputs.add_metadata(term=\"median_color_chip_width\",\n",
    "                         datatype=float,\n",
    "                         value=pcv.outputs.observations[\"default\"][\"median_color_chip_width\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-press",
   "metadata": {
    "id": "characteristic-press"
   },
   "source": [
    "# Back to data extraction! Color data next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-firmware",
   "metadata": {
    "id": "romance-firmware"
   },
   "outputs": [],
   "source": [
    "# Extract color traits from each replicate\n",
    "\n",
    "# Inputs:\n",
    "        #   img          = RGB image for debugging\n",
    "        #   labeled_mask = Grayscale mask with unique pixel value per object of interest\n",
    "        #   n_labels     = Total number expected individual objects (default = 1).\n",
    "        #   colorspaces  = 'all', 'rgb', 'lab', or 'hsv' (default = 'hsv')\n",
    "        #   label        = Modifies the variable name of observations recorded (default = \"default\").\n",
    "\n",
    "color_img = pcv.analyze.color(rgb_img=cc_img,\n",
    "                              labeled_mask=,\n",
    "                              n_labels=,\n",
    "                              colorspaces=\"hsv\",\n",
    "                              label=str(bean_name)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-error",
   "metadata": {
    "id": "scenic-error"
   },
   "source": [
    "# How large is the first bean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-secretary",
   "metadata": {
    "id": "british-secretary"
   },
   "outputs": [],
   "source": [
    "# Index the dictionary of traits to look at the area for one replicate\n",
    "pcv.outputs.observations[f\"{bean_name}_1\"]['area']['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-syndicate",
   "metadata": {
    "id": "vertical-syndicate"
   },
   "source": [
    "## Save results\n",
    "\n",
    "During analysis, measurements are stored in the background in the outputs recorder.\n",
    "\n",
    "This example includes image analysis for 'area', 'convex_hull_area', 'solidity', 'perimeter', 'width', 'height', 'longest_path', 'center_of_mass, 'convex_hull_vertices', 'object_in_frame', 'ellipse_center', 'ellipse_major_axis', 'ellipse_minor_axis', 'ellipse_angle', 'ellipse_eccentricity' using `pcv.analyze.size` and color analysis using `pcv.analyze.color`.\n",
    "\n",
    "Here, results are saved to a CSV file. Filename will update with bean name set at top of this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-height",
   "metadata": {
    "id": "specific-height"
   },
   "outputs": [],
   "source": [
    "pcv.outputs.save_results(f\"{bean_name}.csv\", \"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-viking",
   "metadata": {
    "id": "gorgeous-viking"
   },
   "source": [
    "Now we can go look for the CSV file that we just saved out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-aurora",
   "metadata": {
    "id": "numerical-aurora"
   },
   "source": [
    "<span style=\"color:maroon\">\n",
    "\n",
    "# Duplicate this workflow\n",
    "\n",
    "_Click the (File) tab in the top left corner. (Make a copy ... ) And rename the new jupyter notebook with your next bean type._\n",
    "    \n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
